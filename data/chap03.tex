\chapter{基于局部敏感哈希算法的交互式分析}
\label{cha:china}

与传统的在R树的基础上进行扩展来做在线采样与聚集的思路不同，在本篇文章中，我们采用全新的之前从未在此应用过的局部敏感哈希算法来作为我们索引的数据结构。在这一个章节中，我们首先将会对局部敏感哈希进行一个全面的介绍，包括局部敏感哈希的概念和两个著名的局部敏感哈希算法。其次我们将会详细介绍如何用局部敏感哈希来解决我们本篇文章中的问题，这将分为如何用局部敏感哈希解决基于空间数据的文本分析问题和如何用局部敏感哈希解决在线采样与聚集问题两部分进行介绍。最后，我们将会展示我们用来解决基于空间文本数据的交互式分析问题的局部敏感哈希算法，复合型冲突计数局部敏感哈希(简称C3LSH)。这是一个非常空间高效型的局部敏感哈希算法，比以往的局部敏感哈希算法都更能应对在超大规模空间数据上做分析的瓶颈。

\section{局部敏感哈希算法介绍}
\label{LSHIntro}

\subsection{定义介绍}

局部敏感哈希算法是一种可以将空间上临近的数据以更高的概率哈希到同一个桶的一个哈希算法。为了方便，我们将以数据全集D中的一个数据点的位置o为中心，r为半径的球用$ B(o,r) $来表示。$ B(o,r)={q \in R_d | \parallel o,q \parallel \le r} $. 那么，一个将$ d $维空间$ R_d $映射到某个空间$ U $的局部敏感哈希族$ H $能被规范化定义如下：

\begin{definition}
	
	{\bf 局部敏感哈希}
	
	一个函数族$ H $能被称为$ (r,cr,p_1,p_2) $敏感当且仅当对于任意的两个点$ o,q \in R_d$以及任意的哈希函数$ h \in H $，满足
	
	\begin{enumerate}[(1)]
		
		\item 若满足$ q \in B(o,r) $，那么有$ Pr_H[h(o)=h(q)] > p_1 $。
		
		\item 若满足$ q \notin B(o,cr) $， 那么有$ Pr_H[h(o)=h(q)] < p_2 $。 
		
		\item $ c > 1 $
		
		\item $ p_1 > p_2 $
		
	\end{enumerate}
	
\end{definition}

其中所有属于$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数族的函数都可以被称为$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数。

\subsection{原理简述}

通过向量形式构造的局部敏感哈希的理论基础是p-稳定分布~\cite{PS31}。p-稳定分布可以被规范化定义如下:

\begin{definition}
	{\bf p-稳定分布}
	
	一个在实数域$ R $上的分布$ G $能够被称为$ p $稳定的，当且仅当存在这样一个$ p $使得对于任意的$ n $个实数$ v_1,v_2\dots v_n $和独立同分布的在分布$ G $下的随机变量$ X_1,X_2\dots X_n $，复合变量$ \sum_{i} v_iX_i $ 和复合变量$ (\sum_{i} |v_i|^p)^{\frac{1}{p}}X $有着相同的分布。其中，$ X $是一个有着$ G $分布的随机变量。
\end{definition}

现在已经可以证明~\cite{PS31},对于任意的$ p \in (0,2] $, p-稳定分布是存在的。特别地，

\begin{enumerate}[$ \bullet $]
	
	\item 柯西分布，概率密度函数为$ f(x) = \frac{1}{\pi (1+x^{2})} $， 是1稳定的。
	
	\item 高斯分布，概率密度函数为$ f(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2} $，是2稳定的。
	
\end{enumerate}

通过运用p-稳定分布，我们可以人工生成一个$ d $维度的向量$ \vec{a} $。这个向量$ \vec{a} $的每个分量都是一个来自p-稳定分布的随机向量。由之前的结论，对于任意两个在$ d $维度空间中的向量$ \vec{v_1},\vec{v_2} $, $ (\vec{a}\cdot\vec{v_1} - \vec{a}\cdot\vec{v_2}) $的分布和$ l_p(\vec{v_1},\vec{v_2}) $是一样的。其中$ X $是一个与$ \vec{a} $的分量相同分布的随机变量，$ l_p(\vec{v_1},\vec{v_2})$是向量$\vec{v_1},\vec{v_2}$在$ l_p $空间上的距离。基于以上的观察，有研究工作者~\cite{lazy18}提出了下面所述的在$ l_p $距离使用的局部敏感哈希族：对于$ d $维度空间空间中的任意一个点，将其投影到一条随机的直线$ \vec{a} $上。这条直线被等距离的分为一个个段，投影后落在同一个段内的点将会在被局部敏感哈希函数哈希到一个桶内。该$ l_p $空间上的局部敏感哈希函数可以被正式地定义为

\begin{equation}
h(\vec{v}) = \lfloor \frac{\vec{a} \cdot \vec{v}+b}{r_0}\rfloor, 
\end{equation}

其中，映射向量$ \vec{a} $是通过选取每个分量为p-稳定分布的随机函数来构造的向量。

对于给定的 $\vec{v_1},\vec{v_2} \in R_d$，不妨设$ s = l_p(\vec{v_1},\vec{v_2}) $。那么向量$ \vec{v_1},\vec{v_2} $在一个哈希函数$ h $下冲突的概率可以表示为：

\begin{equation}
p(s,r_0) = \int_{0}^{r_0}\frac{1}{s}f_p(\frac{t}{s}(1-\frac{t}{r_0}))dt, 
\end{equation}

其中，$ f_p $是p-稳定分布绝对值的概率密度函数。函数$ p(s,r_0) $在$ r_0 $固定的时候随着$ s $单调递减。因此前面定义的局部敏感哈希函数族在$ l_p $空间上是$ (1,c,p_1,p_2) $敏感的。并且有$ p_1 = p(1,r_0), p_2-p(c,r_0) $。对于某些特殊的$ p $值例如$ p=1 $或$ p=2 $，我们甚至可以用相应的概率密度函数来计算出具体的概率来~\cite{lazy18}：

\begin{enumerate}
	
	\item 对于柯西分布$ (p=1) $，我们有
	
	\begin{equation}
	p(s,r_0) = 2\frac{arctan(r_0/s)}{\pi} - \frac{1}{\pi(r_0/s)}ln(1+(r_0/s)^2),
	\end{equation}
	
	\item 对于高斯分布$ (p=2) $，我们有
	
	\begin{equation}
	\label{GaussPr} 
	p(s,r_0) = 1 - 2norm(r_0/s) - \frac{2}{\sqrt{2\pi}(r_0/s)}(1-e^{-(r^2/2s^2)}),
	\end{equation}
	
\end{enumerate}

这里$ norm $表示标准正态分布的概率密度函数的积分。

以上为局部敏感哈希的定义及部分理论基础，这将在后面的部分被我们用来进行实验参数的计算和算法复杂度及准确度的评估。因为实际问题需求，在接下来的部分，我们讨论的问题将基于$ l_2 $空间也就是欧拉空间。

局部敏感哈希被用来解决的最常见的问题就是近似最近邻居查询，被定义为：

\begin{definition}
	{\bf $ N(\vec{q},k,c) $问题}
	
	对于一个给定的数据集$ D $，一个点$ \vec{q} \in R_d $，和一个参数$ k $，一个近似比例$ c $，一个c-近似k个最近邻居搜索将返回k个点的序列，这个序列可以表示为$ N(\vec{q},k,c) = \vec{o_1},\vec{o_2}\dots\vec{o_k} $，序列中的点的排序是按照该点和查询$ \vec{q} $的距离降序排序的。也就是说，$ \vec{o_i} $是在c-近似下与查询$ \vec{q} $第i近的邻居。我们设$ \vec{o^*_1},\vec{o^*_2}\dots\vec{o^*_k} $是真实的，精确的查询$ \vec{q} $的k个最近邻居，并且同样按照降序排序。那么$ dist(\vec{o_i},\vec{q}) \le (c\times dist(\vec{o^*_i},\vec{q}) $对于所有的$ i \in [1,k] $成立。
	
	其中$ dist(\vec{o_i},\vec{q}) $表示向量$ \vec{o_i} $ 和 $ \vec{q} $在欧式空间中的距离。
	
\end{definition}

多种不同形式的局部敏感哈希都被应用到了这个问题当中，接下来我们将挑选两个比较具有代表性的局部敏感哈希方法进行介绍。我们将介绍的两种局部敏感哈希算法分别为：精确欧式局部敏感哈希(E2LSH)~\cite{lazy18*}和冲突计数局部敏感哈希(C2LSH)~\cite{lazy21}。

\subsection{精确欧式局部敏感哈希(E2LSH)}

精确欧式局部敏感哈希是一个相当经典的局部敏感哈希算法，也是第一个被用在映射向量式局部敏感哈希函数中局部敏感哈希算法。这个算法刚提出来的时候是为了解决欧式空间上的$ R(\vec{q},r,c) $问题的，这个问题规范化定义如下：

\begin{definition}
	{\bf $ R(\vec{q},r,c) $问题}
	
	对于一个给定的数据集$ D $，一个点$ \vec{q} \in R_d $，和一个半径$ r $，一个近似比例$ c $，一个$ R(\vec{q},r,c) $问题将会在命题：	
	\begin{multline*}
		{\centering \exists\vec{o^*},\vec{o^*}\in D\land\vec{o^*}\in B(\vec{q},r)}
	\end{multline*}	
	成立时，返回一个数据集$ D $中的点$ \vec{o} $ 满足 $ \vec{o} \in B(\vec{q},cr) $。若命题不成立，则返回空集。
\end{definition}
	
可以看出，$ R(\vec{q},r,c) $问题是$ N(\vec{q},k,c) $问题的一个细分。精确欧式局部敏感哈希通过以下方式来解决$ N(\vec{q},k,c) $问题：

首先，该算法将会从$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数族随机选出一系列的哈希函数$ h_1,h_2,\dots h_m $。然后将选出的这些函数结合起来形成一个复合哈希函数$ g $，对于数据集$ D $中的任意一个点$ \vec{v} $有$ g(\vec{v}) = (h_1(\vec{v}),h_2(\vec{v}),\dots h_m(\vec{v})) $。这里，我们就使用复合哈希函数将一个高维的向量转化成了一个m维空间的向量。

由于通过不同哈希函数的复合，距离较远的两个向量被哈希到同一个桶内的概率被大大的降低了。我们使用这个复合函数$ g $对所有的数据进行哈希运算，并将运算出来的桶的编号记录到哈希表当中。为了增加距离较近的两个向量被哈希到同一个“桶”的概率，我们随机选取$ L $个不同的$ g $函数$ g_1,g_2,\dots g_L  $并将上一步骤重复$ L $次并生成$ L $个不同的哈希表。只要两个向量在其中一个$ g $函数里发生冲突我们就认为他们“冲突”到了同一个“桶”内。

相应地，对于一个$ R(\vec{q},r,c) $问题的查询$ \vec{q} $,精确欧式局部敏感将会从$ g_1,g_2,\dots g_L  $中顺次选出$ 3L $个不重复的点。在这$ 3L $种，一旦找到了满足条件的$ \vec{v} \in B(\vec{q},cr) $就立即返回结果。而一个$ N(\vec{q},k,c) $问题则可以通过构造一系列的不同半径$ R(\vec{q},r,c) $问题来解决。



\subsection{冲突计数局部敏感哈希(C2LSH)}

为了避免构建过多的基于不同半径的哈希表，冲突计数局部敏感哈希~\cite{lazy21}被发表了出来。这个算法将原始的哈希函数做了一些调整:

\begin{equation}
	h(\vec{v}) = \lfloor \dfrac{\vec{a} \cdot \vec{v} + b^*}{r_0} \rfloor ,
\end{equation}

其中$ b^* $ 是从$ \lfloor 0, c^{\lceil log_ctd \rceil}r_0^2 \rfloor $里均匀抽取的随机数，$ c $是近似比率。$ t $是向量每个分量的绝对值里所能渠道的最大值，$ d $则是一个这些被哈希的向量的维度。根据前面的结论，可以证明，这个函数族是$ (1,c,p_1,p_2) $敏感的。关于进行这类微调的必要性，相关的原理性叙述可以在~\cite{c2lsh13}中找到，因为与本文要讨论的内容关系不大，此处不再赘述。

为了避免构建过多的基于不同半径的哈希表，该算法首先会用一系列的基于上面的表达式的基础的局部敏感哈希函数，并设置一个非常小的间隔$ r_0 $，然后以此建立一个具体的索引表。接下来，应对各种各样的查询，包括各种不同半径下的$ R(\vec{q},r,c) $问题，冲突计数局部敏感哈希都会使用一开始建立的哈希索引表来取得相应的数据而无需针对不同半径构建新的哈希索引表。这样一个使用同一哈希表来应对不同半径的查询的行为我们称之为虚拟重哈希。对于不同半径下的$ R(\vec{q},r,c) $查询，冲突计数局部敏感哈希将哈希函数调整为

\begin{equation}
	H^r(\vec{v})=\lfloor \dfrac{h(\vec{v})}{r} \rfloor
\end{equation}

容易知道，$ H^r(\vec{v}) $ 是$ (r,cr,p_1,p_2) $敏感的。虚拟重哈希只需要保证能够在原来的哈希表中等价地取到将会出现在$ H^r(\vec{q}) $中的数据，就不需要在专门为半径$ r $构建新的函数。而事实上，$ H^r(\vec{q}) $也确实可以转化为用$ h $函数来表示，其内容里的点等价于原哈希函数在区间$ [\lfloor \dfrac{h(\vec{v})}{r} \rfloor \times r,\lfloor \dfrac{h(\vec{v})}{r} \rfloor \times r + r - 1] $内的桶中所对应的数据。从这里，也可以看出为什么$ r_0 $需要取得尽可能地小。

此外，顾名思义，冲突计数局部敏感哈希使用冲突计数而非是否落入同一个桶来判断两个点能够成为邻居的概率。接下来，我们将引入冲突计数的概念：

\begin{definition}
	{\bf 冲突计数}
	
	一个数据点$ o $对于一个查询$ q $和一组局部敏感哈希函数 $ \beta $的冲突计数就是在$ \beta $内的函数中，能够将数据点$ o $和查询$ q $哈希到同一个哈希桶内的函数的数量。我们不妨用$ collision(o,q,\beta) $ 或者 $ collision(o) $ 来表示数据点$ o $对于一个查询$ q $和一组局部敏感哈希函数 $ \beta $的冲突计数，那么可以用公式表示为：
	
	\begin{equation}
		collision(o) = |{h|h\in \beta \land h(o) = h(q)}|
	\end{equation}
	
\end{definition}

对于每一个$ h_i(i = 1,2\dots m) $， 数据点$ o $和查询$ q $ 冲突在一个桶内都有一个固定的概率，而他们冲突到一定数量的概率即为这个概率的一个组合数运算，显然这个概率是随着数量单调递减的。故我们可以为冲突计数设置一个阈值$ \theta $，当冲突计数 $ collision(o) \ge \theta $ 时，该算法将这个数据点$ o $称为是一个频繁的数据点。

在冲突计数局部敏感哈希算法中，当一个查询$ \vec{q} $到来时，算法将会依次检查这个查询在各个哈希函数中所对应的桶，然后根据冲突计数找出频繁数据点集作为候选数据，再对这些数据依次进行检查，将满足条件的点返回。

因此，在冲突计数局部敏感算法中，$ N(\vec{q},k,c) $问题可以在只用一套哈希表的情况下用一系列不同半径的$ R(\vec{q},r,c) $问题来回答。

理论上，要使得冲突计数局部敏感哈希具备正确且快速查找邻近节点能力，以下两个事件发生的概率必须得到保证：

\begin{enumerate}
	\item $ \mathcal{P}_1 $:如果向量$ \vec{v} $满足 $ \vec{v} \in B(\vec{q},r) $，那么$ \vec{v} $的冲突计数$ collision(\vec{v}) > \theta$
	
	\item $ \mathcal{P}_2 $:所有不属于$ B(\vec{q},cr) $但却又与查询$ \vec{q} $冲突次数超过$ \theta $的点的数量不超过$ \beta|D| $。这里$ D $和前面一样，指的是数据集的全集。
\end{enumerate}

容易想到，冲突计数的阈值$ \theta $是和冲突计数局部敏感哈希所使用的哈希函数的数目是密切相关的。在这里，我们不妨设冲突计数局部敏感哈希所使用的哈希函数数量为$ \eta $。那么对于任何给定的可接受错误率$ \varepsilon $和误检查率$ \beta $, 当$ \theta $ 和 $ \eta $满足一定关系时，冲突计数局部敏感哈希获得最佳性能。

\begin{lemma}
	如果$ \theta $ 和 $ \eta $满足：
	\begin{equation}
	\eta = \lceil \frac{ln\frac{1}{\varepsilon}}{2(p_1-p_2)^2}(1+z)^2 \rceil,	
	\end{equation}
	
	\begin{equation}
	\theta = \frac{zp_1+p_2}{1+z}
	\end{equation}
	
	其中 $ z = \sqrt{\frac{ln\frac{2}{\beta}}{ln\frac{1}{\varepsilon}}} $
	
	那么有$ Pr[\mathcal{P}_1] > 1 - \varepsilon \land Pr[\mathcal{P}_2] > 0.5$~\cite{lazy21}。
\end{lemma}

在这个基础上，我们可以直到存在满足条件的参数使得$ \mathcal{P}_1 $ 和 $ \mathcal{P}_2 $ 都在一个常数概率之上。此时冲突计数局部敏感哈希可以正确且快速地回答$ N(\vec{q},k,c) $问题。


\section{算法可行性讨论}

\label{LSHdiscuss}

在这个部分中我们将会主要用来讨论关于使用局部敏感哈希算法来解决空间范围分析问题的可行性，而在此之前，我们先回顾以下已经有的用来处理空间数据的算法以及他们在处理本文中提出的文本分析问题的弊端。

而之前的一些处理空间数据的交互式分析的算法，比如R树，LS树，RS树等等，他们之所以在解决基于空间数据的文本问题上表现很差，就是因为他们所对应的的数据结构无法处理如此高维的数据，从而只能采取实行基于空间范围的查询的基础上，对满足查询空间范围条件的所有数据依次检查，找出其中文本相关性满足查询要求的数据，并将其依次上报。这种做法不仅查询效率极低，而且还因为采样过程中目标样本过于稀疏，导致准确率也很不尽如人意。

而其他的一些在这样的处理空间数据的数据结构上搭载关键词索引来达到索引空间文本数据的数据结构，如IR树~\cite{irtree}等，因其自身结构无法与现有的交互式分析算法，如RS树等相适应，所以将其强行改造成采样与聚集算法会使得这个算法本身变得异常的低效。同时，这样的数据结构的另外一个缺点就是只能通过关键字索引，这在功能上便受到了很大的局限。

由于文本分析相关的问题涉及到了高维的向量处理。因此我们将目光投向了在高维空间问题上表现十分出色的局部敏感哈希算法。从本质上来说，局部敏感哈希可以被认为是一种降为的手段，将高维的，我们无法处理的数据，通过哈希的方法压缩到低维的，能够被我们索引的空间中来。这种压缩将在概率上很大程度地保证了高维数据原本的特点。这就是局部敏感哈希。

使用局部敏感哈希来进行对空间数据的范围查询与分析，我们可以将其与传统的树状索引结构，R树进行类比。为了叙述方便，在进行类比之前，我们先将原先针对单个局部敏感哈希函数或者函数族的概念进行一些扩展，扩展至局部敏感哈希算法层面。

\begin{definition}
	{\bf 访问}
	
	对于一个局部敏感哈希算法和一个查询$ \vec{q} $, 在回答查询$ \vec{q} $的过程中，算法若对某个数据点的具体内容进行了访问，通常来说，是算法通过访问数据点来检查该数据点是否真的满足查询条件，那么算法对这个数据点所做的行为我们称为访问了这个数据点。
\end{definition}

举例来说，在$ R(\vec{q},r,c) $问题当中，如果一个点$ \vec{d} $被用来检查条件$ dist{\vec{q}, \vec{d}} $是否成立，那么我们就认为这个点已经被访问过了。 在$ N(\vec{q},k,c) $问题当中，如果一个点$ \vec{d} $被用来演算和查询$ \vec{q} $之间的距离来决定是否属于$ k $个最近邻居的时候，这个点也已经被访问过了。

特别地，在精确欧式局部敏感哈希算法中，落在桶$ g_1(\vec{q}),g_2(\vec{q}) \dots g_L(\vec{q}) $ 中的前$ 3L $个点都会被算法访问。在冲突计数局部敏感哈希算法当中，任何满足冲突计数$ collision(\vec{d}) $超过指定阈值$ \theta $的数据点都会被访问。

\begin{definition}
	{\bf $ (r,cr,P_1,P_2) $敏感的局部敏感哈希算法}
	
	一个局部敏感哈希算法能被称为$ (r,cr,P_1,P_2) $敏感的当且仅当对于任意的查询$ \vec{q} \in R_d $以及任意的一个数据点$ \vec{d} \in R_d$，满足
	
	\begin{enumerate}[(1)]
		
		\item 若数据点$ \vec{d} $满足$ \vec{d} \in B(\vec{q},r) $，那么有数据点$ \vec{d}  $被访问到的概率大于$ P_1 $。
		
		\item 若数据点$ \vec{d} $满足$ \vec{d} \notin B(\vec{q},cr) $，那么有数据点$ \vec{d}  $被访问到的概率小于$ P_2 $。 
		
		\item $ c > 1 $
		
		\item $ P_1 > P_2 $
				
	\end{enumerate}

	相应地，对于满足以上条件的函数我们可以将之称为$ (r,cr,P_1,P_2) $敏感的局部敏感哈希算法。
\end{definition}

使用局部敏感哈希来进行对空间数据的范围查询与分析，我们只需要设置r为我们查询范围的半径，使用对应的$ (r,cr,P_1,P_2) $敏感的局部敏感哈希算法，然后将查询范围的中心的位置带入哈希，就可以在桶中搜索我们需要的答案。

对于局部敏感哈希中的一些参数与空间查询的关系，可以认为在上面定义的概率$ P_1 $就是我们这个算法的准确率，由于我们整篇文章的讨论是基于近似的分析算法而进行的，所以这个准确率我们将其维持在97\%以上即可。特别地，在实际使用中，可以通过历史数据的平均准确率来估计整个算法的实际准确率$ 1 - \varepsilon $， 在此基础上对之后的查询结果乘上一个修正参数$ 1 + \varepsilon / 2 $，即可将偏差率减半，将其维持在$ \pm 1.5\% $之内。

而局部敏感哈希算法中的$ P_2 $和算法的访问效率相关。即关系到在使用局部敏感哈希算法应对空间范围查询时，需要访问的点和真正符合范围要求的点所对应的比例。这对应到R树中，即为R树在访问过程中，不得不访问的那些鱼查询范围相交但又不完全查询范围内的节点。于是从这一点考虑，我们希望$ P_2 $尽可能地小。更进一步地，我们可以使用$ P_2 $来对算法性能的上下界进行分析和估计，具体方法我们会在实验部分详细阐述。

\section{基于局部敏感哈希算法的空间文本分析}
\label{lsh1}

在这个部分中，我们致力与找出使用局部敏感哈希来解决基于空间数据的文本分析的具体方法。

对于基于空间数据的文本分析问题，我们要做的就是将这个问题转化为一个在空间中寻找邻近点的问题。

让我们再一次回顾我们要解决的核心问题的定义：对于一个给定的查询文档$ q $，一个给定的范围半径$ r $以及一个给定的范围中心$ c $，求出满足$ dist(c,L_d) < r \land Sim_q(d) > \phi $的数据点d的数目。

将这个问题转化为一个在空间中寻找邻近点的问题可以分成两部分来解决，第一步是将数据文档$ d $以及其位置信息$ L_d $转化为一个向量$ V_d $，第二步是将查询条件从$ dist(c,L_d) < r \land Sim_q(d) > \phi $转化为 $ dist(V_d,V_q) < \mathcal{r} $。

\subsection{将空间文本数据转化为向量}

值得注意的是，文档$ d $的位置信息$ L_d $已经是一个向量的形式了。另一方面，对于文本信息，我们在前面的预备知识中已经提到过，运用向量空间模型的方法，可以将一个文档$ d $通过索引词频来转化为一个$ t $维度的空间向量$ v_d $。最简单直接的想法是，我们将转化后的两个向量拼接在一起就可以得到一个合成的新向量。但由于位置信息的向量与文本信息的向量所使用的度量尺度不同，所以在这基础上要给它们加上各自的权重。

于是我们有下式：

\begin{equation}
	\vec{V_d} = (\frac{w_s}{r}\vec{L_d},\frac{w_t}{|\vec{v_d}|}\vec{v_d}),
\end{equation}

其中，$ w_s,w_t $是对应于空间信息和文本信息的权重，r则是在原始的查询问题中，查询范围的空间半径。

因为对于一个相同的局部敏感哈希算法，概率$ P_1,P_2 $是固定的。在这基础上，由于文本向量和空间向量在不同的尺度上的分布关系不同，我们可以通过调整权重$ w_s,w_t $，使得落入$ B(\vec{V_q},cr) $内而又在$ B(\vec{V_q},r) $之外的数据尽可能地小，从而提升算法的效率。

这里面注意到我们将$ d $所对应的文本向量$ \vec{v_d} $归一化了，具体原因我们将在下面一个小节讲到。

\subsection{将空间文本相关性转化为空间距离}

由于之前我们就已经将空间相关性定义为向量在空间距离中的接近了，所以这个转化的关键就在于将$ Sim_q(d) > \phi $转化成空间距离的问题。函数$ Sim_q(d) $的真实意义是向量$ v_q $和向量$ v_d $间的夹角的余弦值。根据这两个向量生成的定义，向量中的每个分量代表都是一个索引词在对应的文档中出现的频率，都是非负的。因此这两个向量的夹角不会超过九十度。当我们将这两个向量的都进行归一化处理的时候，归一化的向量将会落到同一个球内，这时候这两个向量之间的距离和他们的夹角将会成严格的正相关。相应地，因为夹角不超过九十度，所以他们之间的距离和他们的余弦值成严格的负相关。因此，我们只要找到一个与参数$ \phi $相对应的$ \phi^{'} $，那么$ Sim_q(d) > \phi $就可以被等价地转化为$ dist(normalize(\vec{d}),normalize(\vec{q})) < \phi^{'} $。

基于我们之前构造的向量$ \vec{V_d} = (\frac{w_s}{r}\vec{L_d},\frac{w_t}{|\vec{v_d}|}\vec{v_d}) $，不妨设$ \mathcal{r} = \sqrt{w_s^2 + w_t^2\phi^{'2}} $, 那么$ dist(c,L_d) < r \land Sim_q(d) > \phi $就可以被顺利地转化为 $ dist(V_d,V_q) < \mathcal{r} $。

注意到这一步并不是一个等价的转化，这事实上是将一个求长方形范围内数据的问题变成了求包围长方形的最小椭圆的范围内的数据的问题。所以我们会以转化后的模型来构造局部敏感哈希表，但在实际判断的时候，仍会用原先的条件判断其余查询要求是否符合。此外，也因为这一步的偏差，算法实际的准确率会比计算出来的要高一些。

由于在基于空间数据的文本分析问题当中，查询范围时常会变动，查询的半径也会有不同的改变。因此对于那些适用于单个半径的局部敏感哈希算法，我们需要运行一系列的局部敏感哈希算法去建造基于不同半径的哈希表，这里，我们给出一种不同半径的选举方法。

首先，我们选取一个较小的半径$ r_0 $，然后构造等比数列$ r_0, r_1 = r_0\tau, \dots r_{n-1}=r_0\tau^{n - 1} $，其中等比数列的最后一个半径能够满足所有的查询要求。注意这里只是原始查询中的空间上的半径，我们利用之前描述到的方法，转成我们局部敏感哈希函数所要处理的向量空间上的半径$ \mathcal{r}_0, \mathcal{r}_1 \dots \mathcal{r}_{n-1} $，然后可以使用一系列的局部敏感哈希函数算法构造出$ n $个不同的哈希表：$ (\mathcal{r}_0,c\mathcal{r}_0,P_1,P_2) $敏感，$ (\mathcal{r}_1,c\mathcal{r}_1,P_1,P_2) $敏感...$ (\mathcal{r}_{n-1},c\mathcal{r}_{n-1},P_1,P_2) $敏感。

面对一个基于空间数据的文本分析的查询，我们根据其指定的查询范围的半径$ r $选取对应的局部敏感哈希函数，我们找到一个$ i $使得$ r $ 满足$ r_{i-1} < r < r_{i} $，若$ r < r_0 $则令$ i = 0 $，然后我们就可以使用$ (\mathcal{r}_i,c\mathcal{r}_i,P_1,P_2) $敏感的哈希函数算法来对查询进行解答。

由于$ r < r_{i} $，落在$ B(c,r) $内的点必定会落在$ B(c,r_i) $内，相应地也就会被$ (\mathcal{r}_i,c\mathcal{r}_i,P_1,P_2) $敏感的哈希算法所找到。所以这个算法是正确的。同时因为半径的几何级数增长，我们需要构造的局部敏感哈希算法的数量可以被限制在一个比较小的范围。在算法的性能上，因为文本相关性的衡量尺度是不变的，并且在实验中文本相关性的权重要比空间相关性大不少，所以使用等比近似半径的算法来计算查询所需要的计算时间平均来说不会超过使用精确半径的算法所需要的计算时间的$ (1+\frac{\tau - 1}{2})^2 $倍。

\section{基于局部敏感哈希算法的交互式分析}
\label{lsh2}
	接下来，在这一个部分，我们将会讨论如何将局部敏感哈希算法应用于交互式分析。为了使得局部敏感哈希适用于交互式分析我们给每个点分配了一个独立的整数id。这个整数id是从区间$ (0, MAX] $中随机抽取的不重复的数字。其中$ MAX $是一个非常非常大的整数，比可能产生的数据量要大很多。在运行局部敏感哈希算法来构建哈希表的时候，我们将这些id存在哈希表的桶中，作为对每个数据的唯一索引。然后，在每个桶中，我们把桶内的id进行排序处理。这些id可以让我们非常方便地进行随机抽样处理。
	
	每当一个查询到来时，局部敏感哈希算法将会运行数次，每次局部敏感哈希访问的数据都不同。具体来说，我们每次算法运行的时候，我们都只会访问id在特定区间的数据，例如说第一次运行的时候，我们访问的数据是id落入区间$ (0, 0.01 \times MAX] $的数据。因为id在开始的时候就是完全随机分配的，所以这里的数据等价于数据全集中一个概率为1\%的样本。在第一次局部敏感哈希算法运行结束的时候，算法将会将所找到的满足查询要求的数据的数目乘以100，并将结果返回，这时候我们就得到了第一个估计值。紧接着，算法继续运行，第二次算法将会访问落入区间$ (0.01 \times MAX, 0.02 \times MAX] $中的数据，将得到的结果与之前运行的结果加起来，然后根据所访问过的总区间做一个参数修正，把结果乘以百分之五十，然后返回给用户。重复这一过程，直到用户将整个算法终止或者所有的数据都已经被访问过。
	
	通过这一的方法实现的交互式分析得到的是离散的更新结果，但仅管如此，只要设计合理的区间安排可以使得用户的需求被完全满足。
	
	在算法描述，为了表述方便，我们用算法多次运行来描述基于局部敏感哈希算法的交互式分析方法。实际上，算法可以只运行一次。在算法从哈希桶中取出数据的时候，因为在哈希桶中的id已经事先被排好序，所以只需要在发现id大于区间右端的时候，转向下一个哈希函数的哈希表去取数据，当所有哈希表都取完之后，返回结果，并回到第一个哈希表从上一次的位置开始接着去数据来进行下一轮的判断。从这个过程中我们可以看出，他们之间的切换代价是很小的，因此对局部敏感哈希算法的数据进行区间划分使得其能够满足交互式查询不断返回结果的需求对性能是几乎没有损害的。
	
	从算法的结构和可扩展性而言，使用$ (0, MAX] $区间的随机数作为数据的标识将会使得插入和删除操作需要的时间为常数。我们只需要新分配或者删除一个随机数并通过对插入或删除的数据的id的哈希运算修改对应桶中的内容即可。
	
	此外，在需要分析的数据量极大时，我们不得不将一部分哈希表存在外存里的时候，可以通过id区间划分的方式，将每个哈希表中id在一定区间内的数据搬至硬盘中。这时内存中的数据也是数据全集的一个随机样本，从而使得算法正确性可以不受太大影响。
 

\section{复合型冲突计数局部敏感哈希算法(C3LSH)}
\label{C3LSH}

到目前为止，我们已经讨论了如何使用局部敏感哈希来解决我们的问题。然而，我们要解决的问题还有一个很显著的特点，就是数据规模极大。在数据规模极大的条件下，原先的存在的局部敏感哈希算法的弊端被放大了很多，以至使其无法理想地在现实场景中应用到基于大规模空间数据的交互式文本分析这一问题上来。在此，我们将呈现一种新的局部敏感哈希算法，复合型冲突计数局部敏感哈希算法来解决这一问题。在这一部分中，我们将简单地讨论现有的局部敏感哈希的弊端，然后引进我们的局部敏感哈希算法。

\subsection{算法瓶颈分析}

在讨论现有的哈希方法的弊端之前，我们先介绍局部敏感哈希算法查询中，触碰的概念。

\begin{definition}
	{\bf 触碰}
	
	对于一个局部敏感哈希算法和一个查询$ \vec{q} $, 在回答查询$ \vec{q} $的过程中，算法若存在对某个数据点有关信息的运算，包括不访问数据而只是对数据的id进行的运算，我们都认为这个算法触碰到了这个数据点。
	
\end{definition}

仍然以两个经典的算法来举例，在精确欧式局部敏感哈希算法中，落在桶$ g_1(\vec{q}),g_2(\vec{q}) \dots g_L(\vec{q}) $ 中的前$ 3L $个点都会被算法触碰，虽然这些桶中还有更多的点，但算法实际上在取到第$ 3L $的时候就会中止了，而不会对其后面的点进行任何的操作，所以在该算法中只有前$ 3L $个点是被触碰到的，这时候被访问的数据与被触碰的数据是一样的。但在冲突计数局部敏感哈希算法当中，所有在哈希桶$ H^r_1(\vec{q}),H^r_2(\vec{q}) \dots H^r_\eta(\vec{q}) $内的数据点都会被算法所触碰，因为算法需要根据数据点的id来统计该数据点的冲突计数是否超出了阈值。

随着现在数据的爆炸式增长，在处理超大规模空间数据时，我们通常面对的是十亿甚至百亿数量级的数据。而在过去的局部敏感哈希算法的研究当中，研究实验所用的处理$ N(\vec{q},k,c) $问题的数据集的规模通常在万这个数量级上。所以基于他们的算法，通常需要建立上千甚至上万张哈希表来使得算法在高效的同时保有较高的准确度。而对于十亿级别的数据，一千张哈希表对应的就是至少一万亿个id。若每个id按照长整型算，就是8TB的数据量。这还忽略了数据结构带来的开销的理想计算。8TB的哈希表是无法完全保存在内存当中的。在这种情况下，硬盘的IO将直接成为算法的瓶颈，算法的性能将被大大的降低。

因此，我们对局部敏感哈希参数的选定就从根据要求的$ P_1,P_2 $以及一些准确度参数计算所需要的哈希函数的数目变成了限定哈希函数的数量，在准确度可以接受的范围内，使得运行时间尽可能地段，换句话说，也就是使得$ P_2 $尽可能地低。

除了空间的限制之外，极大数据规模的条件下，还有一个很重要的问题就是触碰的成本变高了。在之前的局部敏感哈希研究里，他们对于时间效率的评估通常都会忽略掉触碰数据的成本。因为通常来说，处理$ N(\vec{q},k,c) $问题所面对的数据集都拥有很高的维度，因此访问一个数据点要比触碰一个数据点开销大得多。而对于我们所讨论的空间中的文本分析问题中，有很多的应用场景都是在一些轻量级的文本上做分析。虽然索引词汇可能有几万甚至几十万，但轻量级文本通常词汇量在几十上百左右，用空间向量模型对这类文本生成的向量里绝大部分分量都是零，对此类向量做计算的计算成本实际上非常之低。加上很多硬件对于向量运算的支持，这就使得触碰数据的成本变得不可忽略。

触碰数据计算时间的不可忽略性直接导致了一些依赖于通过对哈希桶内的数据进行大量筛选减少访问的数据点从而提高算法性能的局部敏感哈希算法，比如冲突计数局部敏感哈希算法难以应用。

以最经典的冲突计数局部敏感哈希算法来说，冲突计数局部敏感哈希在建立哈希表的时候由于只使用了单个哈希函数而非复合哈希函数，因此在每个哈希表中，与查询向量落入同一个桶内的数据量是很大的。算法通过设置冲突的阈值来使得访问的数据量大大减少，但其所需要触碰的数据量却远远高于平常的哈希函数。在应对几十亿数量的超大数据集时，对触碰数据的处理，即对每个id冲突计数的运算直接地成为了算法效率的瓶颈所在。

\subsection{核心思想}

针对上面所提到的问题，我们提出来复合型冲突计数局部敏感哈希算法，这个算法使用了更多层的哈希结构，从而使得算法可以在哈希表构建较少的情况下达到很高的效率和准确率。

冲突计数局部敏感哈希的核心思想就是将精确欧式局部敏感哈希算法与冲突计数局部敏感哈希算法结合起来。

对于所有的局部敏感哈希算法，将多个局部敏感哈希以不同方式组合起来的目的就在于拉伸概率。将基础的$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数中的$ p_1 $ 与 $ p_2 $之间的距离不断拉大。在实验中我们发现，比起增加组合的哈希函数的数目，增加其组合的层次能够在拥有较少的哈希函数时更大程度地将两个概率拉伸开来。也就是说增加组合的层次能够使得整个哈希算法具有更高的效率。这是算法设计上解决空间成本问题的一个核心思想。

与冲突计数局部敏感哈希不同，复合型局部敏感哈希算法虽然也使用了冲突计数，但却没有让触碰数据的计算量成为算法的瓶颈。复合型局部敏感哈希算法因为在底层使用了复合局部敏感哈希函数，使得落入同一个桶内的数据极大地减少了。同时通过对阈值等参数的调整，复合型局部敏感哈希算法将触碰数据的开销和访问数据的开销较好地平衡了起来，从而使得算法整体达到最优效率。


\subsection{核心算法描述}

首先，复合型冲突计数局部敏感哈希算法的核心哈希函数不变，可以被定义为

\begin{equation}
h(\vec{v}) = \lfloor \frac{\vec{a} \cdot \vec{v}+b}{r_0}\rfloor, 
\end{equation}

其中，向量$ \vec{v} $我们想要哈希的输入向量。映射向量$ \vec{a} $是通过选取每个分量为高斯分布下的随机数来构造的向量。$ b $则是在区间$ (0,r_0] $上均匀抽取的一个随机数。$ r_0 $则是我们需要调整的参数之一。


基于上面的表达式，我们得到一个$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数族，其中$ p_1,p_2 $通过我们在预备知识中提到的公式\ref{GaussPr}进行计算。c则是我们用来调整的参数之一。接下来，在这个$ (r,cr,p_1,p_2) $敏感的局部敏感哈希函数族中，我们将随机选出一系列的哈希函数$ h_1,h_2,\dots h_m $。然后将选出的这些函数结合起来形成一个复合哈希函数$ g $。

这时候，对于数据集$ D $中的任意一个点$ \vec{v} $有$ g(\vec{v}) = (h_1(\vec{v}),h_2(\vec{v}),\dots h_m(\vec{v})) $。我们用这个复合的哈希函数$ g(\vec{v}) $来完成对所有数据点的映射，并将映射结果存储到哈希表中。

类似地，我们用同样的方法随机构造出$ L $个不同的$ g $函数$ g_1,g_2,\dots g_L  $并将上一步骤重复$ L $次并生成$ L $个不同的哈希表。这时候，我们所构造的哈希表的数量$ L $是和我们整个算法所需要占用的内存开销正相关的。


基于这些复合的局部敏感哈希函数$ g_1,g_2,\dots g_L $，我们使用冲突计数的方法来衡量两个数据点足够接近的概率。即，当一个查询$ \vec{q} $到来时，算法将会依次检查这个查询$ \vec{q} $在各个哈希函数中所对应的桶$ g_1(\vec{q}),g_2(\vec{q}),\dots g_L(\vec{q}) $，然后统计各个桶内各个id出现的次数。特别地，在应用交互式分析的id区间划分的方法时，每一轮的运算会统计各个桶内落在特定id区间的id出现的次数。对于那些冲突计数超过阈值$ \theta $的点，我们将会对其进行访问，并将报告或者统计那些满足查询条件的点。

特别地，当我们将参数m设置为1的时候,复合型冲突计数局部敏感哈希算法和普通的冲突计数局部敏感哈希算法是等价的。而当我们将阈值参数$ \theta $设置为0的时候，复合型冲突计数局部敏感哈希算法和精确欧式局部敏感哈希算法是等价的。这在理论上说明了在适当的参数选举下，复合型冲突计数从根本上是不可能比这两种算法拥有更差的表现的。在实验部分，我们将会用数据体现他们之间的显著差别。


\begin{algorithm}
	\caption{A}
	\label{alg:A}
	\begin{algorithmic}
		\STATE {set $r(t)=x(t)$} 
		\REPEAT 
		\STATE set $h(t)=r(t)$ 
		\REPEAT
		\STATE set $h(t)=r(t)$ 
		\UNTIL{B} 
		\UNTIL{B}
	\end{algorithmic}
\end{algorithm}













